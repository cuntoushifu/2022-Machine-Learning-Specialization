{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可选实验：逻辑回归的代价函数\n",
    "\n",
    "## 目标\n",
    "在这个实验中，您将：\n",
    "- 检查逻辑回归的代价函数的实现并使用它。"
   ],
   "id": "2ebc706c2c914a30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from lab_utils_common import  plot_data, sigmoid, dlc\n",
    "plt.style.use('./deeplearning.mplstyle')"
   ],
   "id": "5f5c7d13d9b36d81"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "让我们从决策边界实验中使用的相同数据集开始。"
   ],
   "id": "596c081f4f511929"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])  #(m,n)\n",
    "y_train = np.array([0, 0, 0, 1, 1, 1])                                           #(m,)"
   ],
   "id": "f8a0e1a87f37cc43"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将使用一个辅助函数来绘制这些数据。标签为 $y=1$ 的数据点显示为红色叉号，而标签为 $y=0$ 的数据点显示为蓝色圆圈。"
   ],
   "id": "cc50beb12998b10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(4,4))\n",
    "plot_data(X_train, y_train, ax)\n",
    "\n",
    "# Set both axes to be from 0-4\n",
    "ax.axis([0, 4, 0, 3.5])\n",
    "ax.set_ylabel('$x_1$', fontsize=12)\n",
    "ax.set_xlabel('$x_0$', fontsize=12)\n",
    "plt.show()"
   ],
   "id": "dcb4fa1564e84bae"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代价函数\n",
    "\n",
    "在之前的实验中，您开发了*逻辑损失*函数。回顾一下，损失函数被定义为适用于一个示例。在这里，您将这些损失组合起来形成**代价函数**，其中包括所有的示例。\n",
    "\n",
    "回想一下，对于逻辑回归，代价函数的形式如下：\n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m} \\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$\n",
    "\n",
    "其中\n",
    "* $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ 是单个数据点的代价，它是：\n",
    "\n",
    "    $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$\n",
    "    \n",
    "*  其中 m 是数据集中的训练示例数量，以及：\n",
    "$$\n",
    "\\begin{align}\n",
    "  f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}) &= g(z^{(i)})\\tag{3} \\\\\n",
    "  z^{(i)} &= \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+ b\\tag{4} \\\\\n",
    "  g(z^{(i)}) &= \\frac{1}{1+e^{-z^{(i)}}}\\tag{5} \n",
    "\\end{align}\n",
    "$$"
   ],
   "id": "5362aeab28d6b00e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-02'></a>\n",
    "#### 代码说明\n",
    "\n",
    "`compute_cost_logistic` 的算法循环遍历所有的示例，计算每个示例的损失并累积总数。\n",
    "\n",
    "请注意，变量 X 和 y 不是标量值，而是形状分别为 ($m, n$) 和 ($𝑚$,) 的矩阵，其中 $𝑛$ 是特征数，$𝑚$ 是训练示例数。\n"
   ],
   "id": "a0d01ab5d9665744"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_logistic(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes cost\n",
    "\n",
    "    Args:\n",
    "      X (ndarray (m,n)): Data, m examples with n features\n",
    "      y (ndarray (m,)) : target values\n",
    "      w (ndarray (n,)) : model parameters  \n",
    "      b (scalar)       : model parameter\n",
    "      \n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        z_i = np.dot(X[i],w) + b\n",
    "        f_wb_i = sigmoid(z_i)\n",
    "        cost +=  -y[i]*np.log(f_wb_i) - (1-y[i])*np.log(1-f_wb_i)\n",
    "             \n",
    "    cost = cost / m\n",
    "    return cost\n"
   ],
   "id": "db44dc9e8ac8758e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the implementation of the cost function using the cell below."
   ],
   "id": "aed7e40e4ae4c938"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tmp = np.array([1,1])\n",
    "b_tmp = -3\n",
    "print(compute_cost_logistic(X_train, y_train, w_tmp, b_tmp))"
   ],
   "id": "c63ee47203b1d93a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**: 0.3668667864055175"
   ],
   "id": "2fe262d07176aa2d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例\n",
    "现在，让我们看看不同的 $w$ 值对代价函数输出的影响。\n",
    "\n",
    "* 在以前的实验中，您绘制了 $b = -3, w_0 = 1, w_1 = 1$ 的决策边界。也就是说，您有 `b = -3, w = np.array([1,1])`。\n",
    "\n",
    "* 假设您想要查看 $b = -4, w_0 = 1, w_1 = 1$ 或 `b = -4, w = np.array([1,1])` 是否提供了更好的模型。\n",
    "\n",
    "让我们首先绘制这两个不同 $b$ 值的决策边界，看看哪一个更适合数据。\n",
    "\n",
    "* 对于 $b = -3, w_0 = 1, w_1 = 1$，我们将绘制 $-3 + x_0+x_1 = 0$（显示为蓝色）\n",
    "* 对于 $b = -4, w_0 = 1, w_1 = 1$，我们将绘制 $-4 + x_0+x_1 = 0$（显示为品红色）"
   ],
   "id": "2b454ecf4ec370"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose values between 0 and 6\n",
    "x0 = np.arange(0,6)\n",
    "\n",
    "# Plot the two decision boundaries\n",
    "x1 = 3 - x0\n",
    "x1_other = 4 - x0\n",
    "\n",
    "fig,ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "# Plot the decision boundary\n",
    "ax.plot(x0,x1, c=dlc[\"dlblue\"], label=\"$b$=-3\")\n",
    "ax.plot(x0,x1_other, c=dlc[\"dlmagenta\"], label=\"$b$=-4\")\n",
    "ax.axis([0, 4, 0, 4])\n",
    "\n",
    "# Plot the original data\n",
    "plot_data(X_train,y_train,ax)\n",
    "ax.axis([0, 4, 0, 4])\n",
    "ax.set_ylabel('$x_1$', fontsize=12)\n",
    "ax.set_xlabel('$x_0$', fontsize=12)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Decision Boundary\")\n",
    "plt.show()"
   ],
   "id": "3e486ac03b6fc1d5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从这个图中可以看出，`b = -4, w = np.array([1,1])` 对于训练数据是一个更差的模型。让我们看看代价函数的实现是否反映了这一点."
   ],
   "id": "bceffd7177c44308"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_array1 = np.array([1,1])\n",
    "b_1 = -3\n",
    "w_array2 = np.array([1,1])\n",
    "b_2 = -4\n",
    "\n",
    "print(\"Cost for b = -3 : \", compute_cost_logistic(X_train, y_train, w_array1, b_1))\n",
    "print(\"Cost for b = -4 : \", compute_cost_logistic(X_train, y_train, w_array2, b_2))"
   ],
   "id": "54713ab6c370a8da"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "\n",
    "Cost for b = -3 :  0.3668667864055175\n",
    "\n",
    "Cost for b = -4 :  0.5036808636748461\n",
    "\n",
    "\n",
    "You can see the cost function behaves as expected and the cost for `b = -4, w = np.array([1,1])` is indeed higher than the cost for `b = -3, w = np.array([1,1])`"
   ],
   "id": "40ef4aecac9b7e0e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 恭喜！\n",
    "在这个实验中，您检查并利用了逻辑回归的代价函数。"
   ],
   "id": "f343131945a55563"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [],
   "id": "b60b50e1d9163cf8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
